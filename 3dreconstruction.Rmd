---
title: "2D to 3D Reconstruction for Virtual Perception"
author: "Sigit Ari Wijanarko, Hendy Irawan"
date: "Saturday, April 04, 2015"
output:
  html_document:
    number_sections: yes
    self_contained: no
---

## Units & Coordinate System

Lihat: [Lumen Units and 2D/3D Coordinate System](coordinates.html)

## 3D Reconstruction

Formula: http://docs.opencv.org/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html

```
s * UV = CM * Rt * XYZ
```

s adalah pembagi dari UV, bila UV = (20, 10, 2) maka u = 20/2 = 10, v = 10/2 = 5.

$$\mathbf{CM} = \left[\begin{array}
{rrr}
f_x &    0 & c_x \\
  0 & -f_y & c_y \\
  0 &    0 &   1
\end{array}\right]
$$

$-f_y$ diminuskan karena di gambar 2D, pojok atas adalah $v=0$ dan bawah adalah misalnya $v=240$ (untuk dimensi 320×240); padahal di 3D bawah adalah $y<0$ dan atas adalah $y>0$.

Untuk mendapatkan $f_x$ dan $f_y$, kita menentukan dulu focal length dan ukuran "sensor".
Anggap focal length ($F$) 35mm. Dan sensor 36mm x 24mm (Full-frame). Resolusi gambar 320×240.

* $s_x$ = image width(px) / sensor width(mm) = 320px / 36mm = 8.9px/mm
* $s_y$ = image height(px) / sensor height(mm) = 240px / 24mm = 10px/mm
* kalo square pixel, harusnya $s_x = s_y$

Maka

* $f_x$ = F * sx = 35mm * 8.9 = 311.1 px
* $f_y$ = F * sy = 35mm * 10 = 350 px
* $c_x$ (image horizontal center) = imageWidth / 2
* $c_y$ (image vertical center) = imageHeight / 2

Maka

```{r}
library(pander)
# 35mm lens on Sony Alpha 7r
focalLength <- 35 #mm
imageWidth <- 320 #px
imageHeight <- 240 #Px
sensorWidth <- 36 #mm
sensorHeight <- 24 #mm
centerX <- imageWidth / 2 #px
centerY <- imageHeight / 2 #px
CM <- matrix(c(focalLength * imageWidth / sensorWidth, 0, centerX,
               0, -focalLength * imageHeight / sensorHeight, centerY,
               0, 0, 1), ncol=3, byrow=TRUE)
pander(CM, caption='camera matrix')
```

Contoh: Samsung Galaxy S4:

* Aperture size F2.2
* Focal length (35mm equivalent): 31 mm --> harus dikonversi ke focal length fisik = 4.3mm (http://www.digified.net/focallength/)
* Camera sensor size: 1/3.06" (diagonal: 0.3268" = 8.3mm, dimensi: 6.64mm x 4.98mm)
* Pixel size: 1.14 μm

```{r}
# Samsung Galaxy S4
focalLength <- 4.3 #mm
imageWidth <- 320 #px
imageHeight <- 240 #px
sensorWidth <- 6.64 #mm
sensorHeight <- 4.98 #mm
center <- c(imageWidth / 2, imageHeight / 2) #px
names(center) <- c('u', 'v')
f <- c(focalLength * imageWidth / sensorWidth, focalLength * imageHeight / sensorHeight)
names(f) <- c('x', 'y')
pander(f)
all.equal(f['x'], f['y'], check.names=FALSE) # harusnya f['x'] ~ f['y'] yaaa!!
CM <- matrix(c(f['x'],       0, center['u'],
                    0, -f['y'], center['v'],
                    0,       0,           1),
             ncol=3, byrow=TRUE)
pander(CM, caption='camera matrix')
```

Kalau sudah punya CM maka perlu membuat joint rotation-translation matrix.

```{r}
theta <- 0*pi # harusnya ini gamma, lihat penjelasan di bawah tentang rotasi 3D
tc <- c(0, 1.0, -1.0)
names(tc) <- c('x', 'y', 'z')
pander(tc)
# rotasi ini sebenarnya masih RZ, belum R
Rt <- matrix(c(cos(theta), -sin(theta), 0, -tc['x'],
               sin(theta),  cos(theta), 0, -tc['y'], 
               0,           0,          1,  tc['z']), # right-handed
             ncol=4, byrow=TRUE)
pander(Rt)
```

Dari sini kita bisa memproyeksikan sebuah titik 3D ke 2D.
Bila sudah tepat, maka untuk dari 2D ke 3D prosesnya dilakukan kebalikannya
(bila diketahui sebuah elemen dari vektor posisi, misalnya elemen Y).

```{r}
                # x    y   -z   1
XYZ <- matrix(c(  0,   1,1.01,  1, # persis di tengah
                  0,   1,   2,  1, # persis di tengah, agak ke depan
                 -1,   1,   2,  1, # depan, agak ke kiri
                  3,   1,   2,  1, # depan, lebih ke kanan
                  0,   2,   2,  1, # depan, atas
                  0,   0,   2,  1, # depan, lebih ke bawah
                 -1,   0,   2,  1, # depan, kiri bawah
                  2,   5,   2,  1, # depan, kanan atas
                  0,   1,   6,  1, # persis di tengah, depan banget
                 -1,   1,   6,  1, # depan banget, agak ke kiri
                  3,   1,   6,  1, # depan banget, lebih ke kanan
                  0,   2,   6,  1, # depan banget, atas
                  0,   0,   6,  1, # depan banget, lebih ke bawah
                 -1,   0,   6,  1, # depan banget, kiri bawah
                  2,   5,   6,  1),# depan banget, kanan atas
              ncol=4, byrow=TRUE)
colnames(XYZ) <- c('x', 'y', '-z', '1')
pander(XYZ)
```

Lalu dikalikan pointnya secara individual:

```{r}
sUV <- t(CM %*% Rt %*% XYZ[14,]) # point ke-14
names(sUV) <- c('u', 'v', 's')
pander(sUV)
if (sUV['s'] != 0) UV <- sUV / sUV['s'] else UV <- sUV
pander(UV)
```

Atau bersama-sama menggunakan matrix:

```{r}
sUV <- t(CM %*% Rt %*% t(XYZ))
colnames(sUV) <- c('su', 'sv', 's')
pander(sUV)
UV <- matrix(ncol = 3, nrow = nrow(sUV))
colnames(UV) <- c('u', 'v', 's')
UV[,'u'] <- sUV[,'su'] / sUV[,'s']
UV[,'v'] <- sUV[,'sv'] / sUV[,'s']
UV[,'s'] <- sUV[,'s']
pander(UV)
```

Hasilnya dapat diplot:

```{r, warning=FALSE}
library(ggplot2)
df <- data.frame(UV)
df$id <- rownames(df)
df$salpha <- min(max(df$s/5, 0), 1)
df$dsize <- pmin(10/df$s, 20)
pander(df)
ggplot(df, aes(x=u, y=v)) + #geom_point(color=rownames(df)) +
  geom_text(aes(label=id, color=id)) + #,size=dsize
  scale_y_reverse() +
  ggtitle('Note that image range is (0,0)..(320,240), and point ke(n) = ke(n+7) cuma beda z')
```

Experimen apabila Rt diganti sedikit:

```{r, warning=FALSE}
t <- c(1, 0, 0)
names(t) <- c('x', 'y', 'z')
pander(t)
Rt <- matrix(c(cos(theta), -sin(theta), 0, t['x'],
               sin(theta),  cos(theta), 0, t['y'],
               0,           0,          1, t['z']),
             ncol=4, byrow=TRUE)
pander(Rt)

# ramean
sUV <- t(CM %*% Rt %*% t(XYZ))
colnames(sUV) <- c('su', 'sv', 's')
#sUV
UV <- matrix(ncol = 3, nrow = nrow(sUV))
colnames(UV) <- c('u', 'v', 's')
UV[,'u'] <- sUV[,'su'] / sUV[,'s']
UV[,'v'] <- sUV[,'sv'] / sUV[,'s']
UV[,'s'] <- sUV[,'s']
#UV

# plot
library(ggplot2)
df <- data.frame(UV)
pander(df)
ggplot(df, aes(x=u, y=v)) + #geom_point(color=rownames(df)) +
  geom_text(label=rownames(df), color=rownames(df)) +
  scale_y_reverse() +
  ggtitle('Note that image range is (0,0)..(320,240), and point ke(n) = ke(n+7) cuma beda z')
```

## Memplot 'lantai'


```{r}
# create 100 lattice points (10x10) spanning from X=-2..+2 and Z =0..10, Y constant = -1
XYZ <- matrix(nrow = 100, ncol=4)
colnames(XYZ) <- c('x', 'y', 'z', 'dummy')
for (i in 0:9) {
  for (j in 0:9) {
    x <- -2 + i*0.4
    y <- -1
    z <- 0 + j*1
    XYZ[i * 10 + j + 1,] <- c(x, y, z, 1)
  }
}
pander(XYZ)
```

Bila ty = 0:

```{r, warning=FALSE}
theta <- 0*pi
t <- c(0, 0, 0)
names(t) <- c('x', 'y', 'z')
pander(t)
Rt <- matrix(c(cos(theta), -sin(theta), 0, t['x'],
               sin(theta),  cos(theta), 0, t['y'],
               0,           0,          1, t['z']),
             ncol=4, byrow=TRUE)
pander(Rt)

# ramean
sUV <- t(CM %*% Rt %*% t(XYZ))
colnames(sUV) <- c('su', 'sv', 's')
#sUV
UV <- matrix(ncol = 3, nrow = nrow(sUV))
colnames(UV) <- c('u', 'v', 's')
UV[,'u'] <- sUV[,'su'] / sUV[,'s']
UV[,'v'] <- sUV[,'sv'] / sUV[,'s']
UV[,'s'] <- sUV[,'s']
#UV

# plot
library(ggplot2)
df <- data.frame(UV)
#df
ggplot(df, aes(x=u, y=v)) + #geom_point(color=rownames(df)) +
  geom_point(aes(color=s, size=10-s), alpha=0.8) +
  scale_y_reverse(limits=c(360, 0), breaks=c(0, 120, 240)) + 
  scale_x_continuous(limits=c(0, 480), breaks=c(0, 160, 320)) +
  ggtitle('2Dimage range is (0,0)..(320,240)')
```

Bila theta = pi/11: (terhadap sumbu z[depan-belakang])

```{r, warning=FALSE}
theta <- pi/11
t <- c(0, 0, 0)
names(t) <- c('x', 'y', 'z')
pander(t)
Rt <- matrix(c(cos(theta), -sin(theta), 0, t['x'],
               sin(theta),  cos(theta), 0, t['y'],
               0,           0,          1, t['z']),
             ncol=4, byrow=TRUE)
pander(Rt)

# ramean
sUV <- t(CM %*% Rt %*% t(XYZ))
colnames(sUV) <- c('su', 'sv', 's')
#sUV
UV <- matrix(ncol = 3, nrow = nrow(sUV))
colnames(UV) <- c('u', 'v', 's')
UV[,'u'] <- sUV[,'su'] / sUV[,'s']
UV[,'v'] <- sUV[,'sv'] / sUV[,'s']
UV[,'s'] <- sUV[,'s']
#UV

# plot
library(ggplot2)
df <- data.frame(UV)
#df
ggplot(df, aes(x=u, y=v)) + #geom_point(color=rownames(df)) +
  geom_point(aes(color=s, size=10-s), alpha=0.8) +
  scale_y_reverse(limits=c(360, 0), breaks=c(0, 120, 240)) + 
  scale_x_continuous(limits=c(0, 480), breaks=c(0, 160, 320)) +
  ggtitle('2Dimage range is (0,0)..(320,240)')
```

Bila ty = -1: (kamera agak ke atas)

```{r, warning=FALSE}
t <- c(0, -1, 0)
names(t) <- c('x', 'y', 'z')
pander(t)
Rt <- matrix(c(cos(theta), -sin(theta), 0, t['x'],
               sin(theta),  cos(theta), 0, t['y'],
               0,           0,          1, t['z']),
             ncol=4, byrow=TRUE)
pander(Rt)

# ramean
sUV <- t(CM %*% Rt %*% t(XYZ))
colnames(sUV) <- c('su', 'sv', 's')
#sUV
UV <- matrix(ncol = 3, nrow = nrow(sUV))
colnames(UV) <- c('u', 'v', 's')
UV[,'u'] <- sUV[,'su'] / sUV[,'s']
UV[,'v'] <- sUV[,'sv'] / sUV[,'s']
UV[,'s'] <- sUV[,'s']
#UV

# plot
library(ggplot2)
df <- data.frame(UV)
#df
ggplot(df, aes(x=u, y=v)) + #geom_point(color=rownames(df)) +
  geom_point(aes(color=s, size=10-s), alpha=0.8) +
  scale_y_reverse(limits=c(700, 0), breaks=c(0, 120, 240)) + 
  scale_x_continuous(limits=c(0, 1100), breaks=c(0, 160, 320)) +
  ggtitle('2Dimage range is (0,0)..(320,240)')
```

Bila ty = +2: (kamera di bawah lantai)

```{r, warning=FALSE}
t <- c(0, +2, 0)
names(t) <- c('x', 'y', 'z')
pander(t)
Rt <- matrix(c(cos(theta), -sin(theta), 0, t['x'],
               sin(theta),  cos(theta), 0, t['y'],
               0,           0,          1, t['z']),
             ncol=4, byrow=TRUE)
pander(Rt)

# ramean
sUV <- t(CM %*% Rt %*% t(XYZ))
colnames(sUV) <- c('su', 'sv', 's')
#sUV
UV <- matrix(ncol = 3, nrow = nrow(sUV))
colnames(UV) <- c('u', 'v', 's')
UV[,'u'] <- sUV[,'su'] / sUV[,'s']
UV[,'v'] <- sUV[,'sv'] / sUV[,'s']
UV[,'s'] <- sUV[,'s']
#UV

# plot
library(ggplot2)
df <- data.frame(UV)
#df
ggplot(df, aes(x=u, y=v)) + #geom_point(color=rownames(df)) +
  geom_point(aes(color=s, size=10-s), alpha=0.8) +
  scale_y_reverse(limits=c(700, 0), breaks=c(0, 120, 240)) + 
  scale_x_continuous(limits=c(0, 1100), breaks=c(0, 160, 320)) +
  ggtitle('2Dimage range is (0,0)..(320,240)')
```

## 3D Reconstruction from 2D

First, we multiply the CM with Rt:

```{r}
theta <- 0*pi
tc <- c(0, 1.0, -1.0)
names(tc) <- c('x', 'y', 'z')
pander(tc)
#Rt <- matrix(c(cos(theta), -sin(theta), 0, -tc['x'],
#               sin(theta),  cos(theta), 0, -tc['y'],
#               0,           0,          1,  tc['z']), # right-handed
#             ncol=4, byrow=TRUE)
Rt <- matrix(c(cos(theta), -sin(theta), 0, 0,
               sin(theta),  cos(theta), 0, 0,
               0,           0,          1, 0), # right-handed
             ncol=4, byrow=TRUE)
colnames(Rt) <- c('r1', 'r2', 'r3', 't')
pander(Rt)

CMRt <- CM %*% Rt
pander(CMRt)
```

Bila diketahui: u, v, dan y dari object, maka:

```{r}
# case baru: xyz yang diinginkan: point ke-14: c(-1, 0, -6.0) 
# uv(s) adalah: c(118.6, 161.4) -> kalau di imagespace, cuma c(119, 161, dummy=1) dan agak nggak akurat
# y adalah: -1
#
# case lama: xyz yang diinginkan: c(0.8, -1.0, 6.0)
# uv(s) adalah: c(187.6305 154.5382) -> kalau di imagespace, cuma c(188, 154, dummy=1) dan agak nggak akurat
# y adalah: -1
#
#
#

# dy (y object/lantai dikurangi y camera) = 0 - 1 = -1
# s = dy / (y hasil solve)
yObject <- 0 # lantai Lumen: y == 0
yCamera <- 1 # camera 1 meter di atas lantai
dy <- yObject - yCamera
uv <- c(119, 161, 1)
xyz <- solve(qr(CMRt), uv)
names(xyz) <- c('x', 'y', '-z')
pander(xyz)
# s = dy / (y hasil solve)
s <- dy / xyz['y']
pander(s)
# kalikan hasil solve dengan s, maka didapatkan x, y, z sebenarnya KOORDINAT KAMERA
# tinggal translate dengan posisi kamera
# (y bisa dikoreksi sesuai yang sudah diketahui)
# dan tentunya: +- galat
xyz_s <- xyz * s
pander(xyz_s)
names(xyz) <- c('x', 'y', 'z')
xyz['x'] <- xyz_s[1] + tc['x']
xyz['y'] <- xyz_s[2] + tc['y']
xyz['z'] <- -xyz_s[3] + tc['z']
pander(xyz)
```

Terus kita ingin mengetahui tinggi dari objek tersebut,
bila diketahui x,y,z,u,v dari kaki, lalu v dari ujung kepala.

```{r}
uv.head = c(188, 140, 1) # tingginya 14 pixel di camera
xyz.head <- solve(qr(CMRt), uv.head)
names(xyz.head) <- c('x', 'y', 'z')
pander(xyz.head)
# s sudah didapatkan di atas
# kalikan hasil solve dengan s, maka didapatkan xyz sebenarnya
# di mana bs dipastikan bahwa x.head == x.foot, z.head==z.foot
# kalau misalnya ga sama, berarti s-nya salah
# cuma belum dicoba kalau kameranya berotasi...
xyz.head <- xyz.head * s
pander(xyz.head)
pander(c(xyz.head['x'] == xyz['x'], xyz.head['z'] == xyz['z']))
# tinggi orang adalah xyz.head[y] - xyz.foot[y]
person.height <- xyz.head['y'] - xyz['y']
pander(person.height)
```

dan dengan yang cara yang sama, harusnya ini juga bisa digunakan untuk mengetahui lebar (kiri..kanan) dari objek / batas koordinat menurut sumbu x.

## Implementasi di C++

Selain fungsi dasar [matrix multiplication di OpenCV](http://docs.opencv.org/modules/core/doc/basic_structures.html#matrix-expressions), yang dibutuhkan adalah:

1. `qr`: QR Decomposition of Matrix.
2. `solve`: Solve a System of Equations

Ternyata sudah ada, yaitu [bool solve(InputArray src1, InputArray src2, OutputArray dst, int flags=DECOMP_LU)¶](http://docs.opencv.org/modules/core/doc/operations_on_arrays.html?highlight=solve#bool solve(InputArray src1, InputArray src2, OutputArray dst, int flags))

jadi kalo di R:

```{r, eval=FALSE}
xyz <- solve(qr(CMRt), uv)
```

di C++ jadi:

```
bool success = solve(CMRt, uv, xyz, DECOMP_QR);
```

## Pembuktian Model dari Realita Samsung Galaxy S4

### Di MIC lantai 4

* approximate location : -6.890627,107.610220
* ubin : 0.4m x 0.4m
* ukuran ruangan:
  lebar (east-west) max : 11 ubin + 0.24m = 4.4m + 0.24m = 4.64m
  lebar (east-west) min : 0.1m + 10 ubin + 0.24m = 0.1m + 4m + 0.24m = 4.34m
  panjang (north-south) ruangan : 29 ubin + 0.28m = 11.6m + 0.28m = 11.88m
  tinggi ~3m
* pier: deket pintu=0.52m, scale.z=0.62m, di dalam=0.235m.
  jarak dari selatan ke tepi pier: 0.28m + 13ubin + 0.13m = 5.61m
  jarak dari selatan ke center pier: 0.28m + 13ubin + 0.13m + 0.31m = 5.92m
* ketebalan tembok jendela = 0.2m
  ketebalan tembok ke interior = 0.16m
* meja: panjang 1m, tinggi 0.755m, lebar 0.6m

### Di kantor Bippo

* ukuran ruangan:
  dz = (11.66667 + 6.9) * 0.3 = 5.57 m, dengan range: -2...+3.57
  dx = 12 * 0.3 = 3.6 m, dengan range: -1.4 .. +2.2
* Jarak kamera ke tembok (z) = 11.6667 ubin = 11.6667 * 0.3 = 3.5 m
* y kamera = 0.6m. Posisi kamera (0, 0.6, 0).
* y lantai = 0m
* tinggi objek (ubin) = 0.3m
* lebar objek (ubin)  = 0.3m
* rotasi terhadap horizon = awalnya 0 semua, tapi akan di
* posisi objek:
    1. 11 petak dari kamera (0, 0, 3.3)
    2. 10 petak dari kamera (0, 0, 3.0)
    3.  9 petak dari kamera (0, 0, 2.7)
    4.  8 petak dari kamera (0, 0, 2.4)
    5.  7 petak dari kamera (0, 0, 2.1)
    6.  6 petak dari kamera (0, 0, 1.8)
    7.  5 petak dari kamera (0, 0, 1.5)

## Rotasi 3D

Recall pedoman rotasi sebagai berikut:

* Pitch ($R_{cx}$): Looking up and down (0=Straight Ahead, +Up, -Down).
* Yaw ($R_{cy}$): Rotating around (running in circles), 0=North, +West, -East. Kalo di Unreal: 0=East, +North, -South.
* Roll ($R_{cz}$): Rotation about axis of screen, 0=Straight, +CCW, -Clockwise.

Dari [Rotation matrix: In three dimensions](https://en.wikipedia.org/wiki/Rotation_matrix#Basic_rotations):

$$R_cx(\alpha) = \begin{bmatrix}
  1 & 0 & 0 \\
  0 & \cos \alpha & -\sin \alpha \\
  0 & \sin \alpha & \cos \alpha
\end{bmatrix}
R_cy(\beta) = \begin{bmatrix}
  \cos \beta & 0 & \sin \beta \\
  0          & 1 & 0 \\
  -sin \beta & 0 & \cos \beta
\end{bmatrix}
R_cz(\gamma) = \begin{bmatrix}
  \cos \gamma & -\sin \gamma & 0 \\
  \sin \gamma &   cos \gamma & 0 \\
  0           & 0            & 1
\end{bmatrix}
$$

Untuk menggabungkan $R_cx$, $R_cy$, dan $R_cz$ kayaknya urutannya begini:

$$R_c = R_{cz(γ)} R_{cy(β)} R_{cx(α)}
$$

Perhatikan bahwa tugas $[R|t]$ adalah mentranslasi lalu merotasi titik 3D agar berada dalam koordinat kamera.
Setelah didapatkan $R_c$ yaitu rotasi kamera dan $t_c$ yaitu translasi kamera, kita bisa mencari $[R|t]$.
Untuk mendapatkan $[R|\mathbf{t}]$ dari posisi kamera $t_c$ dan rotasi kamera $R_c$, [maka](http://ksimek.github.io/2012/08/22/extrinsic/): ($^T$: transpose)

$$\left[
\begin{array}{c|c}
R & \mathbf{t} \\
\hline
\mathbf{0} & 1 \\
\end{array}
\right]
  = 
\left[
\begin{array}{c|c}
R_c^T & -R_c^{T} t_c \\
\hline
\mathbf{0} & 1 \\
\end{array}
\right]
$$

Dari [Rotation in 3D using OpenCV](http://jepsonsblog.blogspot.com/2012/11/rotation-in-3d-using-opencvs.html):

```
// Rotation matrices around the X, Y, and Z axis
Mat RX = (Mat_<double>(4, 4) <<
          1,          0,           0, 0,
          0, cos(alpha), -sin(alpha), 0,
          0, sin(alpha),  cos(alpha), 0,
          0,          0,           0, 1);
Mat RY = (Mat_<double>(4, 4) <<
          cos(beta), 0, -sin(beta), 0,
          0, 1,          0, 0,
          sin(beta), 0,  cos(beta), 0,
          0, 0,          0, 1);
Mat RZ = (Mat_<double>(4, 4) <<
          cos(gamma), -sin(gamma), 0, 0,
          sin(gamma),  cos(gamma), 0, 0,
          0,          0,           1, 0,
          0,          0,           0, 1);
// Composed rotation matrix with (RX, RY, RZ)
Mat R = RX * RY * RZ;
```
